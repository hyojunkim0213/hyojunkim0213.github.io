---
layout: post
title: "PyTorch Lecture about Machine Learning - 2: Linear Model"
date: 2020-12-27
excerpt: "Sung Kim 님의 PyTorch lecture를 공부하고 작성하고자 합니다."
torch: true
tag:
- PyTorch
comments: false
---

- 지난 강의

[PyTorch Lecture about Machine Learning - 1: Overview]({% post_url 2020-12-27-lecture1 %})

## Machine Learning

지난 lecture1에서 말했듯이, 머신러닝의 기본 아키텍처는 training dataset이 주어지고 이를 컴퓨터가 학습하여 test dataset로 예측하는 것이다.

이를 **Supervised Learning** 이라 한다.


## Model Design

x라는 공부시간이 주어졌을 때, y(점수)가 얼마나 증가하였는지를 예측하는 아키텍처에서 linear relationship을 파악할 수 있다.

linear은 매우 심플하면서도 중요하다.<br>

<img src="https://user-images.githubusercontent.com/28617444/103172224-5b0f7a00-4895-11eb-9333-9b1329346ad0.png" width="300" height="75">

예측값의 의미로 notation은 위의 사진처럼 y^ 을 사용한다.<br>
w는 weight, b는 bias를 나타낸다.

![image](https://user-images.githubusercontent.com/28617444/103172324-ff91bc00-4895-11eb-8f89-e828a294cae7.png)

위의 그림처럼 어떤 line이 가장 적절한 line인지 판단해야 한다. <br>
w와 b는 정해져 있지 않은 random value로 learning을 시작한다.
다양한 random guess를 해가며, 최대한 true line에 가까워지는 방식으로 업데이트 된다.

- 어떻게 line을 평가할까?

![image](https://user-images.githubusercontent.com/28617444/103172420-98c0d280-4896-11eb-9042-748ef6f1630e.png)

각각의 point의 y_hat 값이 y와 얼마나 떨어져있느냐로 판단한다.<br>
이를 error 라고 부르며 **training loss**이다.

따라서, w를 3으로 random 시작하게 되면, 그 때의 예측 값(3,6,9)이 존재하며 이에 따라 loss값(1,4,8)을 계산하게 된다.

그 후, 다음의 업데이트를 진행한다. w=4 가 되고 그 때의 loss를 계산한다.

![image](https://user-images.githubusercontent.com/28617444/103172428-b5f5a100-4896-11eb-8d97-10221aa0576b.png)

이러한 프로세스를 계속하며 **loss가 가장 적어지는 w로 업데이트하는 것이다.**

![image](https://user-images.githubusercontent.com/28617444/103172464-079e2b80-4897-11eb-926e-c2c6475ffd84.png)

모든 data point에 대해 loss를 계산하여 더한 후 개수로 나눠주는 값이 흔히 알고 있는 MSE(mean square error) 인 것이다.

위의 예시는 매우 심플하지만, 많은 파라미터와 많은 가중치가 존재하면 MSE를 최소화하는 최적의 파라미터를 찾기 쉽지 않다. 이를 위해 Loss graph가 도입된다.

![image](https://user-images.githubusercontent.com/28617444/103172516-73809400-4897-11eb-89bd-76c0dbfbd375.png)

loss 를 그래프로 나타냄으로써 최적의 point를 판단할 수 있기 때문이다.

## Code 구현

- x_data와 y_data에 대해 w값을 0~4까지 조절하며, 변화를 보여주는 Code

```python
import numpy as np
import matplotlib.pyplot as plt

x_data = [1.0, 2.0, 3.0]
y_data = [2.0, 4.0, 6.0]


# List of weights/Mean square Error (Mse) for each input
w_list = []
mse_list = []

for w in np.arange(0.0, 4.1, 0.1):
    # Print the weights and initialize the lost
    print("w=", w)
    l_sum = 0

    for x_val, y_val in zip(x_data, y_data):
        # For each input and output, calculate y_hat
        # Compute the total loss and add to the total error
        y_pred_val = forward(x_val)
        l = loss(x_val, y_val)
        l_sum += l
        print("\t", x_val, y_val, y_pred_val, l)
    # Now compute the Mean squared error (mse) of each
    # Aggregate the weight/mse from this run
    print("MSE=", l_sum / len(x_data))
    w_list.append(w)
    mse_list.append(l_sum / len(x_data))

# Plot it all
plt.plot(w_list, mse_list)
plt.ylabel('Loss')
plt.xlabel('w')
plt.show()
```
