---
layout: post
title: "PyTorch Lecture about Machine Learning - 4: Back-propagation and Autograd"
date: 2020-12-28
excerpt: "Sung Kim 님의 PyTorch lecture를 공부하고 작성하고자 합니다."
torch: true
tag:
- PyTorch
comments: false
---

- 지난 강의

1. [PyTorch Lecture about Machine Learning - 1: Overview]({% post_url 2020-12-27-lecture1 %})
2. [PyTorch Lecture about Machine Learning - 2: Linear Model]({% post_url 2020-12-27-lecture2 %})
3. [PyTorch Lecture about Machine Learning - 3: Gradient Descent]({% post_url 2020-12-28-lecture3 %})

## Chain Rule

매우 복잡한 네트워크에서는 계산량이 많아지고 관계식이 복잡해져 각 파라미터들의 gradient를 계산하기 힘들다.

따라서, chain rule의 개념이 도입된다.

![image](https://user-images.githubusercontent.com/28617444/103220958-d7bd5980-4964-11eb-9e94-173f25a719ee.png)

df/dx 을 계산하려면 두가지 function으로 나누어 계산할 수 있다.<br>
즉, f가 loss function일 때, Loss에 대한 Gradient 를 구하기 위해서는 여러 개의 gradient를 계산해야 하지만 chain rule을 통해 그저 값만 안다면 combine하여 곱하면 된다.  
![image](https://user-images.githubusercontent.com/28617444/103221419-eb1cf480-4965-11eb-9b68-6d108f609aa3.png)

## Back Propagation 과정

1. Forward pass x=2, y=3

real input이 주어지며 그저 f 함수에 의해 계산된다.

![image](https://user-images.githubusercontent.com/28617444/103221507-30d9bd00-4966-11eb-99e8-57cb609299c2.png)

2. local gradient를 계산한다.

f 함수를 알기에 쉽게 그림 상의 y를 계산할 수 있다.
따라서, 마지막 Loss에 대한 미분값이 그림처럼 5(예시) 라고 주어지면, local gradient를 계산하여 쉽게 모든 파라미터들에 대한 Loss에 대한 미분값을 구할 수 있다.

![image](https://user-images.githubusercontent.com/28617444/103221676-8a41ec00-4966-11eb-97e7-b2ac84728637.png)


## Computational Graph

Backpropagation의 하나의 예시이다.

![image](https://user-images.githubusercontent.com/28617444/103221835-ed338300-4966-11eb-94f1-0c6273de6873.png)

그림처럼, x,y, w가 주어졌을 때 value를 **forward pass**를 통해 구할 수 있다.

그저 compute 하고 value를 기억한다.

그 후, **Backward propagation**을 진행한다.

![image](https://user-images.githubusercontent.com/28617444/103222129-4b606600-4967-11eb-99ce-fab554ab29b7.png)

d(loss)/d(s) 를 구하여 s를 대입하여 local gradient(-2)를 계산한 후,<br>
d(y^-y)/d(y^) 을 계산한다. 이 때, chain rule에 의해 앞에서 구한 -2와 그 때의 local gradient를 곱하여 계산한다.

마지막으로 d(loss)/d(w)를 계산하며 이러한 모든 과정이 chain rule에 의해 진행된다.

## Code 구현

PyTorch는 back propagation 과정을 미분해주기 때문에, 편리하다.<br>
requires_grad option에 따라, gradient descent 적용시 변수 값(Variable)을 바꿀지 그대로 둘지를 정할 수 있다.
```python
import torch
from torch.autograd import Variable


x_data = [1.0, 2.0, 3.0]
y_data = [2.0, 4.0, 6.0]

w = Variable(torch.tensor([1.0]), requires_grad=True) # any random value
```

코드에서는 w는 업데이트를 위해 변수 값을 바꾸는 의미로 True로 설정하였다.

forward 함수는 지난시간에 다뤘듯이 매우 심플하다.
Loss function 역시 오차의 제곱을 반환하는 함수이다.



```python
# our model forward pass
def forward(x):
    return x * w

# Loss function
def loss(y_pred, y_val):
    return (y_pred - y_val) ** 2
```

이제 실제 학습 과정이다. <br>

각각의 input data가 들어오면, forward 함수를 지나 l 로 loss를 계산한 값을 넣어준다.<br>
- l. backward()<br>
그 후, l로부터 backpropagation을 실행한다.<br>
이 코드를 진행하지 않으면 backpropagation 과정을 진행하지 않는다.
w.grad.item() 을 통해 그 때의 gradient 값을 확인할 수 있다.


back propagation에서의 gradient값은 매번 w에 추가되어 업데이트된다.

추가적으로, 매번 Backward() 실행 시, gradient가 업데이트 되므로 0으로 초기화해주어야 한다.

```python
# Before training
print("Prediction (before training)",  4, forward(4).item())

# Training loop
for epoch in range(10):
    for x_val, y_val in zip(x_data, y_data):
        y_pred = forward(x_val) # 1) Forward pass
        l = loss(y_pred, y_val) # 2) Compute loss
        l.backward() # 3) Back propagation to update weights
        print("\tgrad: ", x_val, y_val, w.grad.item())
        w.data = w.data - 0.01 * w.grad.item()

        # Manually zero the gradients after updating weights
        w.grad.data.zero_()

    print(f"Epoch: {epoch} | Loss: {l.item()}")

# After training
print("Prediction (after training)",  4, forward(4).item())
```
